{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b13b6d5-6507-4a52-ad01-4c74a7f341c6",
   "metadata": {},
   "source": [
    "### Overview\n",
    "Supervised learning is a core building block for training a large language model.\n",
    "\n",
    "How it works:\n",
    "A language model is built by using supervised learning (x→y) to repeatedly predict the next word.\n",
    "\n",
    "E.g.:   *My favorite food is a bagel with cream cheese and lox.*\n",
    "\n",
    "| **Input x** | **Output y** |\n",
    "| --- | --- |\n",
    "| My favorite food is a | bagel |\n",
    "| My favorite food is a bagel | with |\n",
    "| My favorite food is a bagel with | cream |\n",
    "| ………… | ….. |\n",
    "\n",
    "Given a large training set (billions of words) and make the dataset `input x` , `output y` . Repeatedly ask the model to learn the prediction of what’s next word.\n",
    "\n",
    "Getting from base LLM to instruction tuned LLM:-     \n",
    "\n",
    "- Train a base LLM on lot of data. (take months)\n",
    "- Further train the model:\n",
    "    - Fine tune on examples of where the output follows input instructions. (tries to predict next words)\n",
    "        \n",
    "        To improve the quality of LLM’s output-\n",
    "        \n",
    "    - Obtain human-ratings of the quality of different LLM outputs, on criteria such as whether it is useful, honest and harmless.\n",
    "        \n",
    "        Further\n",
    "        \n",
    "    - Tune LLM to increase probability that it generates the more highly rated outputs (using RLHF: Reinforcement Learning with human Feedback)\n",
    "\n",
    "---\n",
    "\n",
    "Note: It is not repeatedly predict next word, it predicts next token.\n",
    "\n",
    "The words that often most used with human.\n",
    "\n",
    "E.g. \n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"./imgs/image.png\" alt=\"image\" width=\"550\" />\n",
    "</div>\n",
    "\n",
    "Some of the words that are not much used like ‘Prompting’\n",
    "\n",
    "E.g. \n",
    "\n",
    "![image.png](./imgs/image_1.png)\n",
    "\n",
    "Here, the single word ‘Prompting’ contains 3 tokens.\n",
    "\n",
    "Suppose I have the word `lollipop` and I want to reverse this, then the LLM might look this word as\n",
    "\n",
    "![image.png](./imgs/image_2.png)\n",
    "\n",
    "> ChatGPT is not see individual letters, it sees three tokens. So it is hard to respond this word into correct reverse order.\n",
    "> \n",
    "\n",
    "To overcome such problems, we can use `l-o-l-l-i-p-o-p` then it reverse this and prints.\n",
    "\n",
    "![each letter is token](./imgs/image_3.png)\n",
    "\n",
    "each letter is token\n",
    "\n",
    "> For english language: 1 token is around 4 characters.\n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "Token limits:\n",
    "\n",
    "- Different models have different limits on the number of tokens in the input (’context’) + output (’completion’).\n",
    "- gpt-3.5-turbo ~4000 tokens\n",
    "\n",
    "---\n",
    "\n",
    "Supervised learning:  ——\n",
    "\n",
    "Prompt based AI:—————"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656204c-d591-4728-aaae-eef6ab013fc0",
   "metadata": {},
   "source": [
    "### Language Models, the Chat Format and Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77d0bdd5-007d-4638-bd37-bacdab4e3848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from utils import get_completion, get_completion_with_openai, get_completion_with_openai_from_messages, get_completion_from_messages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "251eb0d8-e97e-4813-aa93-4b0f91117062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The letters in the word \"lollipop\" are:\n",
      "\n",
      "l-o-l-l-i-p-o-p\n",
      "\n",
      "Reversing them, I get:\n",
      "\n",
      "p-o-p-i-l-l-o-l\n"
     ]
    }
   ],
   "source": [
    "response = get_completion_with_openai(\"Take the letters in lollipop \\\n",
    "and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05be77-8355-410a-8911-408b6e534571",
   "metadata": {},
   "source": [
    "Overview: The model is capable of reversing the string. This was not correctly classifies a year ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8627a41-93c9-4869-ad1f-e7d11d4a62dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the garden, oh so bright,\n",
      "Grew a carrot, full of delight!\n",
      "It danced with joy, its orange glow,\n",
      "A happy veggie, don't you know!\n",
      "It laughed and beamed, in the sun's warm light,\n",
      "A merry carrot, what a wondrous sight!\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who\\\n",
    " responds in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user', \n",
    " 'content':\"\"\"write me a very short poem\\\n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "response = get_completion_with_openai_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ec1d9c4-6b72-475f-99a5-66c25f6f982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a sunny garden, a bright orange carrot named Carl sprouted with joy, feeling grateful for the warm soil and loving care of the gardener who nurtured him to grow into the happiest, most vibrant carrot he knew.\n"
     ]
    }
   ],
   "source": [
    "# length\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'All your responses must be \\\n",
    "one sentence long.'},    \n",
    "{'role':'user',\n",
    " 'content':'write me a story about a happy carrot'},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaf78f23-e922-41ed-8147-4e354e8887a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the sunny garden of Gleefulville, a plump and juicy carrot named Carlley Carpino lived a life of pure bliss, basking in the warm rays of the sun and singing silly songs about his love of being a crunchy snack.\n"
     ]
    }
   ],
   "source": [
    "# combined\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':\"\"\"You are an assistant who \\\n",
    "responds in the style of Dr Seuss. \\\n",
    "All your responses must be one sentence long.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a story about a happy carrot\"\"\"},\n",
    "] \n",
    "response = get_completion_from_messages(messages, \n",
    "                                        temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046fc3d9-781f-4cfb-8ec9-dbf5d24acc82",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84f55535-bcbd-4ab1-a55c-2abd66625f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_completion_and_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7cf4c93-2400-4d63-a4fa-732cc5d0c479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the garden, oh so bright,\n",
      "Grew a carrot, full of delight!\n",
      "It danced with joy, with a twirl and a spin,\n",
      "A happy carrot, with a heart that would win!\n",
      "\n",
      "Its orange hue, shone like the sun,\n",
      "As it beamed with glee, having fun!\n",
      "It sang a song, of pure delight,\n",
      "A happy carrot, on this merry night!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who responds\\\n",
    " in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a very short poem \\ \n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "response, token_info = get_completion_and_token_count(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2dba3a7e-9561-417d-bc75-5db73c9faf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 41, 'completion_tokens': 81, 'total_tokens': 122}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8ae94-bd56-415b-898e-cc5b6565655d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
